{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"V4WLwMvx8J6O","executionInfo":{"status":"ok","timestamp":1694666152217,"user_tz":300,"elapsed":3369,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","from torchtext.datasets import IMDB\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","train_iter = IMDB(split='train')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vzzOtWM88J6S","executionInfo":{"status":"ok","timestamp":1694666178897,"user_tz":300,"elapsed":26685,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}}},"outputs":[],"source":["# build vocabulary with the raw training dataset\n","\n","tokenizer = get_tokenizer('basic_english')\n","train_iter = IMDB(split='train')\n","\n","def yield_tokens(data_iter):\n","    for _, text in data_iter:\n","        yield tokenizer(text)\n","\n","vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=['<unk>'])\n","vocab.set_default_index(vocab['<unk>'])"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MmAdXAqG8J6T","executionInfo":{"status":"ok","timestamp":1694666178898,"user_tz":300,"elapsed":119,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dcdeb217-1cf3-4642-c25f-7e11bf18eeef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["100683"]},"metadata":{},"execution_count":3}],"source":["# number of vacabs\n","len(vocab)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"qVU6NGWh8J6T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694666178898,"user_tz":300,"elapsed":115,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}},"outputId":"4775ec98-b6f7-4769-f7cb-cc62b5842968"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[131, 9, 40, 464]"]},"metadata":{},"execution_count":4}],"source":["# list of tokens  -> integers\n","vocab(['here', 'is', 'an', 'example'])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"CO01ok8q8J6T","executionInfo":{"status":"ok","timestamp":1694666178899,"user_tz":300,"elapsed":114,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}}},"outputs":[],"source":["# process raw data (one review) -> list of integers\n","text_pipeline = lambda x: vocab(tokenizer(x))\n","label_pipeline = lambda x: int(x) - 1\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yuHlcue38J6U","executionInfo":{"status":"ok","timestamp":1694666194445,"user_tz":300,"elapsed":134,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n","\n","def collate_batch(batch):\n","    label_list, text_list, offsets = [], [], [0]\n","\n","    for _label, _text in batch:\n","        label_list.append(label_pipeline(_label))\n","        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n","        text_list.append(processed_text)\n","        offsets.append(processed_text.size(0))\n","\n","    label_list = torch.tensor(label_list, dtype=torch.int64)\n","    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","    text_list = torch.cat(text_list)\n","    return label_list.to(device), text_list.to(device), offsets.to(device)\n","\n","dataloader = DataLoader(\n","    train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"HFWT9NjF8J6U","executionInfo":{"status":"ok","timestamp":1694666196576,"user_tz":300,"elapsed":3,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}}},"outputs":[],"source":["class MLP(nn.Module):\n","\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","        super(MLP, self).__init__()\n","        self.embedding = nn.EmbeddingBag(vocab_size , embed_dim , sparse=True)\n","\n","        num_layer = 100\n","\n","        self.fc1 = nn.Linear(embed_dim , num_layer)\n","        self.fc2 = nn.Linear(num_layer , num_class)\n","\n","        self.init_weights()\n","\n","    def init_weights(self):\n","\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc1.weight.data.uniform_(-initrange, initrange)\n","        self.fc1.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","\n","        embedded = self.embedding(text, offsets)\n","\n","        return self.fc2(self.fc1(embedded))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"NVoTCtoR8J6V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694666199657,"user_tz":300,"elapsed":1594,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}},"outputId":"738b18d4-0cdc-454a-b322-522d4ccb9ba2"},"outputs":[{"output_type":"stream","name":"stdout","text":["{1, 2}\n"]}],"source":["# number of class -> 2 (1 or 2)\n","# According to examples above, 1 is case of negative review. (Then 2 is positive)\n","print(set([label for (label, text) in train_iter]))\n","num_class = len(set([label for (label, text) in train_iter]))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"3pShx5IE8J6V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1694666200202,"user_tz":300,"elapsed":548,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}},"outputId":"b32d134f-5971-4b6e-d93f-da88f595fe5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP(\n","  (embedding): EmbeddingBag(100683, 200, mode='mean')\n","  (fc1): Linear(in_features=200, out_features=100, bias=True)\n","  (fc2): Linear(in_features=100, out_features=2, bias=True)\n",")\n"]}],"source":["vocab_size = len(vocab)\n","emsize = 200\n","model_linear = MLP(vocab_size, emsize, num_class).to(device)\n","print(model_linear)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"CiYde-zI8J6V","executionInfo":{"status":"ok","timestamp":1694666200202,"user_tz":300,"elapsed":3,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}}},"outputs":[],"source":["import time\n","\n","\n","def train(dataloader):\n","    model_linear.train()\n","    total_acc, total_count = 0, 0\n","    log_interval = 500\n","    start_time = time.time()\n","\n","    for idx, (label, text, offsets) in enumerate(dataloader):\n","        optimizer.zero_grad()\n","        predicted_label = model_linear(text, offsets)\n","        loss = criterion(predicted_label, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model_linear.parameters(), 0.1)\n","        optimizer.step()\n","        total_acc += (predicted_label.argmax(1) == label).sum().item()\n","        total_count += label.size(0)\n","        if idx % log_interval == 0 and idx > 0:\n","            elapsed = time.time() - start_time\n","            print(\n","                \"| epoch {:3d} | {:5d}/{:5d} batches \"\n","                \"| accuracy {:8.3f}\".format(\n","                    epoch, idx, len(dataloader), total_acc / total_count\n","                )\n","            )\n","            total_acc, total_count = 0, 0\n","            start_time = time.time()\n","\n","\n","def evaluate(dataloader):\n","    model_linear.eval()\n","    total_acc, total_count = 0, 0\n","\n","    with torch.no_grad():\n","        for idx, (label, text, offsets) in enumerate(dataloader):\n","            predicted_label = model_linear(text, offsets)\n","            loss = criterion(predicted_label, label)\n","            total_acc += (predicted_label.argmax(1) == label).sum().item()\n","            total_count += label.size(0)\n","    return total_acc / total_count"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ydK5aRKz8J6V","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1694666217665,"user_tz":300,"elapsed":16837,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}},"outputId":"30a309ed-457c-49d1-92b9-b0c77e3de324"},"outputs":[{"output_type":"error","ename":"NotImplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-7c174ac67ca3>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0maccu_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_accu\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtotal_accu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0maccu_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-cb71e5f88777>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouped_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforeach\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_has_foreach_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mnorms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mforeach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'foreach=True was passed, but can\\'t use the foreach API on {device.type} tensors'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'aten::_foreach_norm.Scalar' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::_foreach_norm.Scalar' is only available for these backends: [CPU, CUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at aten/src/ATen/RegisterCPU.cpp:31034 [kernel]\nCUDA: registered at aten/src/ATen/RegisterCUDA.cpp:43986 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:19 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradCPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradCUDA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradHIP: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradXLA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradMPS: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradIPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradXPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradHPU: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradVE: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradLazy: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradMeta: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradMTIA: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradPrivateUse1: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradPrivateUse2: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradPrivateUse3: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nAutogradNestedTensor: registered at ../torch/csrc/autograd/generated/VariableType_2.cpp:17472 [autograd kernel]\nTracer: registered at ../torch/csrc/autograd/generated/TraceType_2.cpp:16726 [kernel]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:148 [backend fallback]\n"]}],"source":["from torch.utils.data.dataset import random_split\n","from torchtext.data.functional import to_map_style_dataset\n","\n","# Hyperparameters\n","EPOCHS = 10  # epoch\n","LR = 5  # learning rate\n","BATCH_SIZE = 64  # batch size for training\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model_linear.parameters(), lr=LR)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n","total_accu = None\n","train_iter, test_iter = IMDB()\n","train_dataset = to_map_style_dataset(train_iter)\n","test_dataset = to_map_style_dataset(test_iter)\n","num_train = int(len(train_dataset) * 0.95)\n","split_train_, split_valid_ = random_split(\n","    train_dataset, [num_train, len(train_dataset) - num_train]\n",")\n","\n","train_dataloader = DataLoader(\n","    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")\n","valid_dataloader = DataLoader(\n","    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")\n","test_dataloader = DataLoader(\n","    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch\n",")\n","\n","for epoch in range(1, EPOCHS + 1):\n","    epoch_start_time = time.time()\n","    train(train_dataloader)\n","    accu_val = evaluate(valid_dataloader)\n","    if total_accu is not None and total_accu > accu_val:\n","        scheduler.step()\n","    else:\n","        total_accu = accu_val\n","    print(\"-\" * 59)\n","    print(\n","        \"| end of epoch {:3d} | time: {:5.2f}s | \"\n","        \"valid accuracy {:8.3f} \".format(\n","            epoch, time.time() - epoch_start_time, accu_val\n","        )\n","    )\n","    print(\"-\" * 59)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bp1NG5nZ8J6W","executionInfo":{"status":"aborted","timestamp":1694666178900,"user_tz":300,"elapsed":113,"user":{"displayName":"Jooyong Lee","userId":"03355881400877097792"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}